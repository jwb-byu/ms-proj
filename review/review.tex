% setup
\documentclass[11pt]{article}
\usepackage[style=ieee,sorting=none]{biblatex}
\usepackage{etoolbox}
\usepackage{fancyhdr} % For custom headers/footers
\usepackage[a4paper, left=0.5in, right=0.5in, top=0.5in, bottom=0.5in, headheight=14pt, headsep=10pt, footskip=14pt]{geometry}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue]{hyperref}
\usepackage{mathptmx} % Use Times New Roman font

% title info
\title{CS 698R Literature Review}
\author{Wesley Borden}
\date{August 12, 2025}

% header/footer
\pagestyle{fancy}
\fancyhf{} % Clear default header and footer
\fancyhead[L]{CS 698R Literature Review} % Left header
\fancyhead[R]{Wesley Borden} % Right header
\fancyfoot[C]{\thepage} % Center footer with page number
\renewcommand{\headrulewidth}{0pt}

% spacing and indentation
\AtBeginEnvironment{document}{\setlength{\parindent}{0.25in}} % Ensure parindent is set for the document
\newcommand{\sectionwithindent}[1]{
    \section*{#1}
    \hspace{\parindent} % Indent the first paragraph
}
\newcommand{\subsectionwithindent}[1]{
    \subsection*{#1}
    \hspace{\parindent} % Indent the first paragraph
}

% other package setup
\addbibresource{review.bib}

% text
\begin{document}

\sectionwithindent{Electrophysiology Data Analysis for Connectomics: An Introduction}

\vspace{-2em}

\subsectionwithindent{Data Science is Central for Advancements in Neuroscience}
% Neuroscience needs data science
In 2018, \textit{Nature Methods} published an article stating that ``Neuroscience is experiencing a revolution'' \cite{pandarinath2018autoencoders}. The article introduced a novel computational approach, implementing a neural network-based model to infer dynamics between active brain cells. As developments in neuroscience continue to unfold, that article is one of many suggesting that computing, automation, data analysis, and machine learning will increasingly be at the core of major research achievements and clinical applications in neuroscience.

% Data science has a big opportunity in biology--specifically neuroscience
Since the design of the transformer architecture in 2017 \cite{vaswani2023attentionneed} and commercialization of scaled machine learning in recent years, large language models (LLMs) have rapidly become a ubiquitous technology \cite{naveed2025llm}. Though much public attention and industry effort has focused on LLMs and other consumer-facing tools, some of the greatest achievements in machine learning are outside the scope of these applications. For example, machine learning applications have made major contributions to computational biology. In that domain, the AlphaFold algorithms have implemented a model similar to the transformer to increase the number of all known protein structures in the world from less than a few hundred thousand to hundreds of millions \cite{jumper2021alphafold, varadi2024alphafolddb}. Just as some of the next decade's greatest achievements in biology and neuroscience will require applications of data science and machine learning, some of the greatest opportunities to innovate with data science and machine learning lie in applications to other fields, including biology and neuroscience.

% Network science is a specific part of data science that is key for neuroscience and connectomics.
Artificial neural networks (ANNs) are not the only technology showing promise for innovative applications to neuroscience. As the nervous system contains a network of connected, interacting neurons, known as a connectome, network science is similarly applicable. Network science provides a mathematical foundation for modeling and analyzing connectomes \cite{emmons2015connectomics, easley2010networks, newman2010networks}, including metrics (e.g., centrality, modularity) and algorithms (e.g., page rank and Louvain) for understanding individual nodes (neurons) and their communities within the network \cite{easley2010networks, newman2010networks}. The foundation of network science is combined with ANNs in graph neural networks (GNNs), including graph autoencoders (GAEs), which use convolutions on a product of the graph's adjacency matrix, degree matrix, and node feature embeddings to establish structure-aware embeddings of each node \cite{velickovic2018graphattentionnetworks, kipf2016gae}. As modern methodological advances increase capacity for collection of high-resolution connectomes, these network science tools are already beginning to be applied to improve understanding of nervous tissue function (e.g., \cite{srinivasan2025gnnconnectome, neudorf2022gnnconnectome}).

% The plan for this paper is to show synergy between data science and neuroscience subfields
This review considers the intersection of subfields in data science and neuroscience, including connectomics, extracellular electrophysiology, brain computer interfaces, neural signal processing, and spike train analysis. In introducing these subfields, I suggest that they have significant potential for synergy in accelerating understanding of microscale processing and distributed systems in the brain. In addition to providing understanding, I propose that these same technologies will offer significant new clinical interventions for a wide variety of nervous system diseases and disorders in coming decades.

\subsectionwithindent{A Connectome Details Neural Connections}
% Define a connectome
The term "connectome" refers to the set of all neural connections in the nervous system, originating in the context of post-human-genome-project ``-omics'' research \cite{ciarrusta2023connectome, mahapatra2010omics, green2015hgp}. The term "biological neural network" (BNN) \cite{yamazaki2022spiking} is also used to reference neural connections, though a BNN may be only a sub-network of the full network--a partial connectome. The field of connectomics is based on a foundational premise that the aggregated structure and function of individual neural connections determines intermediate- and high-level functionality of the brain, including cognitive, behavioral, and neurological outcomes. These aggregated neural connections can be considered as a network, with neurons as nodes and relationships between nodes as edges. Relationships are directional and may be excitatory, inhibitory, or modulatory, with relationship strength varying with the quantity of neurotransmitter released from one cell and the expression of neurotransmitter receptors on the other. Many factors at systemic and subcellular scales regulate the network as it changes over time \cite{ciarrusta2023connectome}. Though a full connectome ideally includes all neurons and all synaptic relationships, connectomes are typically studied at varied scales. A partial connectome includes a sub-network of a complete microscale connectome; a macroscale connectome is a connectome without cellular resolution, resulting in analogs of a network science meta-node and some missing nodes or edges; and a functional connectome is based on functional relationships rather than known physical connections between cells \cite{baxter2023functionalconnectome, blommaert2023structuralconnectome, ciarrusta2023connectome, sejnowski2016nanoconnectomics, elam2021hcp}.

% Microscopy
The gold standard for collection of a connectome is ex-vivo electron microscopy, a method that began to be used in the 1980's \cite{white1986structure, emmons2015connectomics}. The process includes delicate slicing of the tissue and imaging of each slice, followed by stitching visualizations together to identify all neurons and connections. Current methods restrict the scale of this exercise to only small animal models such as C. elegans and drosophila melanogaster \cite{white1986structure, emmons2015connectomics, scheffer2020connectome}. In larger mammals, ex-vivo microscopy has been used to produce partial connectomes from samples of neural tissue, and to produce macroscale connectomes from the full brain \cite{motta2019connectomicreconstruction, helmstaedter2011high, amunts2013bigbrain}. Ongoing methodological advances will likely continue to expand the scope and scale of these processes. While developments are promising, these methods are limited to only ex-vivo research, and microscopy-based connectomics must be combined with in-vivo neural recording to understand functional relationships and work toward clinical interventions.

% MRI and the human connectome project
A major milestone in connectomics was the Human Connectome Project (HCP) \cite{elam2021hcp}, which pioneered methods for collection of human connectomes in-vivo via magnetic resonance imaging (MRI), including functional MRI (fMRI) and diffusion MRI (dMRI). From 2010 to 2019, teams collected a large initial dataset of fMRI-based macroscale connectomes and standardized many processes for large-scale study with MRI. Many projects today continue to iterate and build on the HCP with expanded scope, considering additional populations and analyses. While these methods have proven extremely useful in many research cases, they observe neural activity only indirectly by measuring fluid flow through tissue. Measurement resolution is also restricted by the physical limitations of radiowaves used in MRI devices. As a result, cellular-level activity cannot be measured, and determination of causative relationships between nuclei is limited. For example, excitatory vs. inhibitory relationships typically cannot be identified \cite{hagman2010mriconnectomics}.

\subsectionwithindent{Extracellular Electrophysiology Can Be Optimized for Resolution and Coverage}
% Objectives for new methods in connectomics
Recent advances in electrical engineering and data analysis for in-vivo neural recording adds complementary value to the contributions being made by current microscopy and MRI methods. Neural recording enables more specific identification of functional relationships between cells for a given human or animal during a given period in time, which will likely elucidate cellular underpinnings of high-level function of the nervous system, and build toward improved clinical interventions for many neurological and psychiatric disorders \cite{kobayashi2025connections, zhang2025neds,musk2019integrated, card2024neuroprosthesis}. Important considerations with these advances in neural recording include: (1) recording should have sufficient resolution in space and time to differentiate precise firing activity of individual cells; (2) though whole-brain-recording is unlikely, a maximal spatial area should be targeted, to capture activity from many neurons, including those in different anatomical regions \cite{jun2017probes}; (3) the connections determined by analysis of the recordings will give functional, not necessarily anatomical, relationships \cite{ciarrusta2023connectome}; and (4) collected data must be organized to enable efficient, scalable processing \cite{pachitariu2016kilosort, buccino2020spikeinterface}.

% Intracranial, extracellular electrophysiology recording
Neural recording with a single electrode and a small sample of neural tissue has been used for nearly a century to understand the nervous system \cite{piccolino1997galvani, adrian1928basis}. As methods have evolved and used in animal models, much data has been collected and used to improve understanding about neurons and the brain \cite{ibl2022datarelease, wilson1993ensemble}. During the mid-20\textsuperscript{th} century, methods for preparation and use of electrodes were refined and standardized to optimize accuracy and precision of recorded signals \cite{dowben1953electrode, green1958microelectrode}. Later, multiple electrodes were combined into single devices (e.g., tetrodes) to allow parallel recording at multiple adjacent sites. This enabled greater signal reliability and coverage of multiple cells, exposing the need for efficient and scalable data processing \cite{mcnaughton1983tetrode, wilson1993ensemble, jog2002tetrode}. More recently, Neuropixels probes have been developed to record from hundreds of simultaneously-active channels, each associated with more than one thousand sites available on the hardware after implantation. Multiple probes can be inserted into the brain during an experiment, allowing for simultaneous recording from hundreds to thousands of neurons in-vivo in animal models and in humans \cite{jun2017probes, steinmetz2021probes, paulk2022probes, ibl2022datarelease}. These developments over several decades show ongoing progress toward solving the previously stated problems of spatiotemporal resolution and coverage.

% BCI's are next, and aren't as new as they might seem: VNS, RNS, DBS
As the scope and scale of electrophysiology recording of the brain increases, devices for large-scale data collection are now being developed. In the 1990's, a seminal device was developed at the University of Utah to target a greater surface area ($\approx4mm\textsuperscript{2}$) than would be feasible with single-shank devices by placing electrodes in a grid \cite{maynard1997utaharray}. The greater coverage allowed more information transfer from the brain, powering a useful brain-computer interface (BCI). The Utah Array's technology has been used in humans with quadriplegia and amyotrophic lateral sclerosis (ALS) to control computers and a robotic arm, promising to improve quality of life after years of paralysis or difficulty moving. During initial studies, the device was implanted into the motor cortex, which directly controls voluntary muscle movement, but is not involved with planning or orchestrating movement \cite{kim2008braingate, simeral2011braingate, hochberg2012reach, bacher2015bg}. The technology has been used to carry brain signals past a spinal injury to enable movement of a previously-paralyzed arm \cite{ajiboye2017bciarm}. More recently, intracortical arrays have been implanted into brain regions outside the motor cortex that are associated with higher-level processing that leads to speech, improving communication for an ALS patient by decoding whole words \cite{card2024neuroprosthesis}. Building on the Utah Array and similar intracortical devices, newer BCI devices continue to add more electrodes to optimize spatial resolution and coverage. New devices also implement flexible electrode materials with robotic insertion to optimize electrode placement and minimize impact on neural tissue, improving recovery time after the implantation procedure \cite{musk2019integrated}. As high-bandwidth BCI's approach clinical availability, they will likely complement, and show potential to compete with, existing lower-bandwidth electrode-based medical devices, including vagus nerve stimulation (VNS), deep brain stimulation (DBS), and responsive neurostimulation (RNS) \cite{pertsch2025neuromod, heck2014rns, geller2018rns}. While there is much work left to do, continued advances show potential that future applications will be available for a wide range of neurological, and eventually psychiatric, conditions.

\subsectionwithindent{Advances in Neural Signal Processing Enable Scaled Electrophysiology}
% NSP goals, AP/LFP identification
Regardless of scale, the primary output of electrophysiological recording is a set of voltages, each associated with a time and a recording channel/site. Values are typically organized into a matrix with rows corresponding to channels and columns corresponding to timepoints. With hundreds of channels and thousands of timepoints per second, these matrices can become quite large, so they are often visualized as a heatmap (e.g., \cite[Fig.~1A]{pachitariu2016kilosort}). Initial processing of raw voltage data typically includes separation of the signal by wavelength with a high-pass filter to differentiate local field potential (LFP) voltages resulting from the local environment from action-potential (AP) voltages that correspond to neural firing. This step is often handled on-device for modern electrode technologies \cite{jun2017probes}. Next, AP values are often cleaned with transformations such as common average referencing and spatial whitening to resolve artifacts, noise, and movement of electrodes during recording \cite{pachitariu2016kilosort, pachitariu2024kilosort4}.

% A typical spike sorting pipeline
AP voltage data has been used directly in machine learning models to predict intended behavior (e.g., \cite{musk2019integrated}). While this is appropriate for applications such as BCIs, where fast input/output is needed \cite{todorova2014sorting, christie2015sorting, trautmann2019accurate}, additional spike sorting is required to identify discrete spikes in the action potential signals and cluster them into spike trains, where each cluster's spike train includes the spike times associated with a putative neuron. While many spike sorting algorithms exist and vary by complexity \cite{jog2002tetrode, pachitariu2016kilosort, boussard2023dartsort}, we will consider the conceptual details of steps in one prototypical algorithm that has proven ideal for large datasets, known as KiloSort \cite{pachitariu2016kilosort, pachitariu2024kilosort4}. In the KiloSort algorithm, AP voltage spikes are identified based on shifting values in adjacent spatiotemporal measurements (e.g., adjacent rows and columns in the AP space-by-time matrix). These adjacent measurements are vectorized and grouped by similarity via template deconvolution and clustering. Multiple iterations of template deconvolution and clustering have been implemented since 2016, with improvements including capacity for spikes to be split or merged in scenarios such as spike overlap \cite{pachitariu2016kilosort,pachitariu2024kilosort4}. The KiloSort algorithm has been used for spike sorting in a large animal model dataset collected over several years \cite{ibl2022datarelease, ibl2022iblsorter} and featured in a standardized library of leading spike sorting algorithms \cite{buccino2020spikeinterface}. As spike sorting processes continue to improve, precise identification of neurons and their spiking times will then enable spike train analysis (described next) to identify and analyze neuronal network dynamics in-vivo.

\subsectionwithindent{Spike Train Analysis Produces Functional Connectomes}
% Intro

% Cross correlation
% perkel1967crosscor, moore1970crosscor, kobayashi2025connections

% Transfer Entropy, Granger Causality
% kobayashi2025connections



\begin{equation}
    T_{X \to Y} = \sum_{y_t,\, y_h,\, x_h}
    p(y_t, y_h, x_h)
    \log_{2} \frac{p(y_t \mid y_h, x_h)}{p(y_t \mid y_h)}
\end{equation}


\begin{equation}
    L \propto \log N
\end{equation}







% modeling: GLM, CLDS

% Next generation, association with behavior: autoLFADS, NEDS
% pandarinath2018autoencoders, keshtkaran2022large, zhang2025neds, vareberg2024wisconsinbins




% tons of algorithms exist (cite a bunch. Ranging from wisconsin-madison binning to autoencoders to GLM.)


\subsectionwithindent{Conclusion}
% briefly mention that we're done talking through details. The big picture is that 20 years from now I anticipate a revolution in medical devices and understanding of neural circutry to be beyond stopping, and similar in scope and size and hype to the modern AI boom. And it will all be powered by data science.

\newpage
\printbibliography

\end{document}
