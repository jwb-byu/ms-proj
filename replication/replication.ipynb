{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848d4645",
   "metadata": {},
   "source": [
    "# Demonstration of Spike Train Analysis Algorithm Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9b8e2",
   "metadata": {},
   "source": [
    "Wesley Borden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580eb1c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1da28b",
   "metadata": {},
   "source": [
    "The second objective of my MS project is to \"Implement and experiment with 3-5 algorithms for electrophysiology-based identification of connectome subgraphs with International Brain Lab small animal data\". Here, I demonstrate the use of a set of python functions I have developed to replicate these algorithms. I also show simple visualizations of the identified networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc884f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d668e5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brainbox.io.one import SpikeSortingLoader\n",
    "from iblutil.util import Bunch\n",
    "from one.alf.io import AlfBunch\n",
    "from one.api import OneAlyx, ONE  # Docs: https://int-brain-lab.github.io/ONE/\n",
    "\n",
    "from cc.cc import cross_correlate\n",
    "# from gu.utils import *\n",
    "# from te.te import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2ee8e",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e445d80",
   "metadata": {},
   "source": [
    "IBL API as demonstrated in `.../data-demo/nsp_data_demo_jwb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50633e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_alyx: OneAlyx = ONE(\n",
    "    cache_dir=\"/Users/wesley/GitHub/BYU/ms-proj/tmp/one-cache\",  # any directory where temporary files can be synced\n",
    "    base_url=\"https://openalyx.internationalbrainlab.org\",  # base url for the API\n",
    "    password=\"international\",  # public-access password\n",
    "    silent=True,  # don't print progress, etc.\n",
    ")  # most 'type: ignore' are because IBL's libraries are less strict on types # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = \"2024_Q2_IBL_et_al_BWM_iblsort\"  # tag for most recent data release ()\n",
    "all_sessions: list = one_alyx.search(  # list of sessions\n",
    "    tag=data_tag, query_type=\"remote\"\n",
    ")  # type: ignore\n",
    "n_sessions = len(all_sessions)\n",
    "print(f\"Session count: {n_sessions}\")\n",
    "print(f\"Session example: {all_sessions[0]}\")\n",
    "\n",
    "all_insertions: list = one_alyx.search_insertions(  # list of insertions\n",
    "    tag=data_tag, query_type=\"remote\"\n",
    ")  # type: ignore\n",
    "n_insertions = len(all_insertions)\n",
    "print(f\"Insertion count: {n_insertions}\")\n",
    "print(f\"Insertion example: {all_insertions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab61f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same one for consistency between this demo and other IBL demos\n",
    "pid_i = 534\n",
    "pid: str = str(all_insertions[pid_i])\n",
    "pid_details: tuple[str, str] = one_alyx.pid2eid(pid)\n",
    "eid, p_name = pid_details\n",
    "\n",
    "print(f\"Probe ID: {pid}\")\n",
    "print(f\"Probe Name: {p_name}\")\n",
    "print(f\"Experiment ID: {eid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebf0bb",
   "metadata": {},
   "source": [
    "### Load Spike-Sorted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020072f",
   "metadata": {},
   "source": [
    "As demonstrated in `.../data-demo/nsp_data_demo_jwb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f430e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_loader = SpikeSortingLoader(pid=pid, one=one_alyx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b66175",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_sorting_data: tuple[AlfBunch, AlfBunch, Bunch] = spike_loader.load_spike_sorting()  # type: ignore\n",
    "spikes, clusters, channels = spike_sorting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df = spikes.to_df()\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_wrangled: dict = {}\n",
    "for k, v in clusters.items():\n",
    "    if v.ndim == 1:\n",
    "        clusters_wrangled[k] = v\n",
    "    elif v.ndim == 2:\n",
    "        for k_sub in v:\n",
    "            v_sub = v[k_sub]\n",
    "            clusters_wrangled[k_sub] = v_sub\n",
    "    else:\n",
    "        raise ValueError(\"Bad dimensions\")\n",
    "\n",
    "\n",
    "clusters_df: pd.DataFrame = pd.DataFrame(clusters_wrangled)\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_df = AlfBunch(channels).to_df()\n",
    "channels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_clusters: AlfBunch = spike_loader.merge_clusters(spikes, clusters, channels)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ea0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_clusters_df = merged_clusters.to_df()\n",
    "merged_clusters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c99613",
   "metadata": {},
   "source": [
    "### Timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2185e",
   "metadata": {},
   "source": [
    "As demonstrated in `.../data-demo/nsp_data_demo_jwb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 150  # seconds since beginning the electrophysiology recording\n",
    "end_time = 152  # seconds since beginning the electrophysiology recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df_timeframe = spikes_df[start_time <= spikes_df[\"times\"]]\n",
    "spikes_df_timeframe = spikes_df_timeframe[spikes_df_timeframe[\"times\"] <= end_time]\n",
    "spikes_df_timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba34d1",
   "metadata": {},
   "source": [
    "### Determine Bin Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf9da0",
   "metadata": {},
   "source": [
    "In `.../data-demo/nsp_data_demo_jwb.ipynb`, we used high-resolution bins that slowed down processing. For spike train analysis, we can tune bin size as a hyperparameter. We will use a 10ms bins size, which aligns with a prior study (Moore, 1970, Statistical Signs of Synaptic Interaction in Neurons, https://doi.org/10.1016/S0006-3495(70)86341-X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc061cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_per_s = 100 # each bin is 10ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce258c",
   "metadata": {},
   "source": [
    "### Wrangle to Clusters-by-Time Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b433e",
   "metadata": {},
   "source": [
    "Adapted from `.../data-demo/nsp_data_demo_jwb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_channel_map = (\n",
    "    merged_clusters_df[[\"cluster_id\", \"channels\"]]\n",
    "    .copy()\n",
    "    .sort_values(by=\"channels\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    "    .reset_index(drop=False)\n",
    "    .rename(inplace=False, columns={\"index\": \"cluster_channel_id\"})\n",
    ")\n",
    "cluster_channel_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df_timeframe = spikes_df_timeframe.merge(\n",
    "    cluster_channel_map, left_on=\"clusters\", right_on=\"cluster_id\", how=\"left\"\n",
    ")\n",
    "spikes_df_timeframe[\"time_bin\"] = (np.floor((spikes_df_timeframe[\"times\"] - start_time) * bins_per_s)).astype(int)  # bin by microsecond\n",
    "spikes_df_timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_spikes_matrix = np.zeros(\n",
    "    (cluster_channel_map.shape[0], ((end_time - start_time) * bins_per_s))\n",
    ")  # type: ignore\n",
    "clusters_spikes_matrix[\n",
    "    (\n",
    "        spikes_df_timeframe[\"cluster_channel_id\"].max()\n",
    "        - spikes_df_timeframe[\"cluster_channel_id\"].values\n",
    "    ),\n",
    "    spikes_df_timeframe[\"time_bin\"].values,\n",
    "] = int(1)  # 1 represents a spike # type: ignore\n",
    "clusters_spikes_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6caa56b",
   "metadata": {},
   "source": [
    "### Visualize Spike Trains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe1b11",
   "metadata": {},
   "source": [
    "As demonstrated in `.../data-demo/nsp_data_demo_jwb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "axs.scatter(\n",
    "    spikes_df_timeframe[\"times\"].values,  # type: ignore\n",
    "    spikes_df_timeframe[\"cluster_channel_id\"].values,  # type: ignore\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    "    c=\"#000000\",\n",
    "    marker=\"s\",\n",
    ")\n",
    "\n",
    "axs.set_title(\"Putative Neural Spikes\")\n",
    "axs.set_xlabel(\"Time (s)\")\n",
    "axs.set_ylabel(\"Putative Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fe173",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bc7be",
   "metadata": {},
   "source": [
    "Everything to this point has been copied or adapted from `.../data-demo/nsp_data_demo_jwb.ipynb`. Now we will show how to use the data to identify a biological neural network: a partial connectome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d10305",
   "metadata": {},
   "source": [
    "## Cross Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e685403",
   "metadata": {},
   "source": [
    "Cross correlation involves a sliding dot product of two vectors that represent parallel spike trains. The resulting distribution includes outliers if there is a significant correlation between the two spike trains. This is implemented in `cross_correlate`, which returns a category as follows:\n",
    "\n",
    "|Category | Meaning |\n",
    "|---|---|\n",
    "|  1| relationship |\n",
    "|  0| no relationship |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Comparing a spike train to itself returns {cross_correlate(clusters_spikes_matrix[0], clusters_spikes_matrix[0])}\")\n",
    "print(f\"Comparing a spike train to a distant spike train returns {cross_correlate(clusters_spikes_matrix[0], clusters_spikes_matrix[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_limit = 10\n",
    "sample_count = 0\n",
    "for i, _ in enumerate(clusters_spikes_matrix):\n",
    "    for j in range(i+1, min(i+100, len(clusters_spikes_matrix))):\n",
    "        if cross_correlate(clusters_spikes_matrix[i], clusters_spikes_matrix[j]):\n",
    "            sample_count += 1\n",
    "            print(f\"Spike train {i} is functionally connected to spike train {j}\")\n",
    "            if sample_count >= sample_limit:\n",
    "                break\n",
    "    if sample_count >= sample_limit:\n",
    "        break\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
